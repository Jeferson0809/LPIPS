# -*- coding: utf-8 -*-
"""LPIPS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JApwJuIVwixIgSCG9OQd3O6jJ6Pe8xUq
"""

!git clone https://github.com/S-aiueo32/lpips-pytorch.git
!git clone https://github.com/Jeferson0809/LPIPS
!mv lpips-pytorch/lpips_pytorch /content/

import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
from pathlib import Path
from PIL import Image, ImageFilter, ImageChops, ImageEnhance
from lpips_pytorch import lpips
import numpy as np

def to_tensor(image):
    return TF.to_tensor(image).unsqueeze(0) * 2 - 1

# Cargar original
img_path = Path("/content/LPIPS/gato.jpeg")
img = Image.open(img_path).convert("RGB")

# Distorsiones (ejemplo)
img_blur_low = img.filter(ImageFilter.GaussianBlur(radius=5))
img_blur_high = img.filter(ImageFilter.GaussianBlur(radius=15))
img_shift = ImageChops.offset(img, xoffset=200, yoffset=150)

# Ruido más fuerte
np_img = np.array(img).astype(np.float32) / 255.0
noise = np.random.normal(0, 0.5, np_img.shape)
np_noisy = np.clip(np_img + noise, 0, 1) * 255
img_noise = Image.fromarray(np_noisy.astype(np.uint8))

# Saturación
enhancer = ImageEnhance.Color(img)
img_saturation = enhancer.enhance(5)

# Tensores
tensor_org = to_tensor(img)
tensor_blur_low = to_tensor(img_blur_low)
tensor_blur_high = to_tensor(img_blur_high)
tensor_shift = to_tensor(img_shift)
tensor_noise = to_tensor(img_noise)
tensor_saturation = to_tensor(img_saturation)

# Calcular LPIPS (como float)
loss = lambda a,b: lpips(a, b, net_type='alex', version='0.1').item()
score_org = loss(tensor_org, tensor_org)  # debe ser ~0
scores = {
    "Original": score_org,
    "Blur Bajo": loss(tensor_org, tensor_blur_low),
    "Blur Alto": loss(tensor_org, tensor_blur_high),
    "Shifting": loss(tensor_org, tensor_shift),
    "White Noise": loss(tensor_org, tensor_noise),
    "Saturation": loss(tensor_org, tensor_saturation),
}

# Pares imagen+score en el orden deseado
imagenes = [
    ("Original", img, scores["Original"]),
    ("Blur Bajo", img_blur_low, scores["Blur Bajo"]),
    ("Blur Alto", img_blur_high, scores["Blur Alto"]),
    ("Shifting", img_shift, scores["Shifting"]),
    ("White Noise", img_noise, scores["White Noise"]),
    ("Saturation", img_saturation, scores["Saturation"]),
]

# Plot: cada imagen con su LPIPS debajo
fig, axes = plt.subplots(2, 3, figsize=(15, 8))
axes = axes.flatten()

for ax, (nombre, imagen, score) in zip(axes, imagenes):
    ax.imshow(imagen)
    ax.set_title(nombre)
    ax.axis("off")
    # colocamos el texto debajo de la imagen usando coordenadas relativas al axes
    ax.text(0.5, -0.12, f"LPIPS: {score:.4f}", transform=ax.transAxes,
            ha='center', va='top', fontsize=11)

# Ajustes para que haya espacio para el texto
plt.subplots_adjust(hspace=0.4, bottom=0.06)
plt.show()